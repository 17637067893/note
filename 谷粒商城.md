版本对应

[版本说明 · alibaba/spring-cloud-alibaba Wiki (github.com)](https://github.com/alibaba/spring-cloud-alibaba/wiki/版本说明)

![image-20210508132210087](G:\note\image\image-20210508132210087.png)

#### 参数校验

######  jsr303

引入依赖

![image-20210509095002322](G:\note\image\image-20210509095002322.png)

![image-20210509095027187](G:\note\image\image-20210509095027187.png)

![image-20210509095043144](G:\note\image\image-20210509095043144.png)

![image-20210509094938881](G:\note\image\image-20210509094938881.png)

```javascript
空检查 
@Null 验证对象是否为null 
@NotNull 验证对象是否不为null, 无法查检长度为0的字符串 
@NotBlank 检查约束字符串是不是Null还有被Trim的长度是否大于0,只对字符串,且会去掉前后空格. 
@NotEmpty 检查约束元素是否为NULL或者是EMPTY.

Booelan检查 
@AssertTrue 验证 Boolean 对象是否为 true 
@AssertFalse 验证 Boolean 对象是否为 false

长度检查 
@Size(min=, max=) 验证对象（Array,Collection,Map,String）长度是否在给定的范围之内 
@Length(min=, max=) Validates that the annotated string is between min and max included.

日期检查 
@Past 验证 Date 和 Calendar 对象是否在当前时间之前，验证成立的话被注释的元素一定是一个过去的日期 
@Future 验证 Date 和 Calendar 对象是否在当前时间之后 ，验证成立的话被注释的元素一定是一个将来的日期 
@Pattern 验证 String 对象是否符合正则表达式的规则，被注释的元素符合制定的正则表达式，regexp:正则表达式 flags: 指定 Pattern.Flag 的数组，表示正则表达式的相关选项。

数值检查 
建议使用在Stirng,Integer类型，不建议使用在int类型上，因为表单值为“”时无法转换为int，但可以转换为Stirng为”“,Integer为null 
@Min 验证 Number 和 String 对象是否大等于指定的值 
@Max 验证 Number 和 String 对象是否小等于指定的值 
@DecimalMax 被标注的值必须不大于约束中指定的最大值. 这个约束的参数是一个通过BigDecimal定义的最大值的字符串表示.小数存在精度 
@DecimalMin 被标注的值必须不小于约束中指定的最小值. 这个约束的参数是一个通过BigDecimal定义的最小值的字符串表示.小数存在精度 
@Digits 验证 Number 和 String 的构成是否合法 
@Digits(integer=,fraction=) 验证字符串是否是符合指定格式的数字，interger指定整数精度，fraction指定小数精度。 
@Range(min=, max=) 被指定的元素必须在合适的范围内 
@Range(min=10000,max=50000,message=”range.bean.wage”) 
@Valid 递归的对关联对象进行校验, 如果关联对象是个集合或者数组,那么对其中的元素进行递归校验,如果是一个map,则对其中的值部分进行校验.(是否进行递归验证) 
@CreditCardNumber信用卡验证 
@Email 验证是否是邮件地址，如果为null,不进行验证，算通过验证。 
@ScriptAssert(lang= ,script=, alias=) 
@URL(protocol=,host=, port=,regexp=, flags=)
```

###### 分组校验

定义空的接口 进行分组

```java
public interface AddGroup {
}
public interface UpdateGroup {
}
```

实体类对参数进行分组

```java
@NotNull(message = "修改必须指定id",groups = {UpdateGroup.class})
    @Null(message = "新增不能指定id",groups = {AddGroup.class})
    @TableId
    private Long brandId;
```

最后 方法上进行标注

```java
@PostMapping("/save")
public R save(@Validated({AddGroup.class}) @RequestBody Entity entity) {
    entityService.save(entity);
    return R.ok();
}

@PostMapping("/update")
public R update(@Validated({UpdateGroup.class})@RequestBody Entity entity) {
    entityService.updateById(entity);
    return R.ok();
}
```



###### 同一异常处理

创建枚举定义异常code和异常信息

```java
public enum  BizCodeEnume {

    UNKNOWN_EXCEPTION(10000,"系统未知样"),
    VAILD_EXCEPTION(10001,"参数格式教养");

    private int code;
    private String msg;

    BizCodeEnume(int code, String msg) {
        this.code = code;
        this.msg = msg;
    }

    public int getCode() {
        return code;
    }

    public String getMsg() {
        return msg;
    }
}
```

异常处理

```java
@Slf4j
@RestControllerAdvice(basePackages = "com.example.demo3.controller") //收集异常数据的所在包
public class ExceptionControllerAdvice {


    //精确匹配异常类型
    @ExceptionHandler(value = MethodArgumentNotValidException.class)
    public R handlerVailException(MethodArgumentNotValidException e){
        log.error("参数问题{},异常类型:{}",e.getMessage(),e.getClass());
        BindingResult bindingResult = e.getBindingResult();
        Map<String,String> errorMap = new HashMap<>();
        bindingResult.getFieldErrors().forEach((fieldError)->{
            errorMap.put(fieldError.getField(),fieldError.getDefaultMessage());
        });
        return R.error(BizCodeEnume.VAILD_EXCEPTION.getCode(),BizCodeEnume.VAILD_EXCEPTION.getMsg()).put("data",errorMap);
    }

    //汇总不能匹配的异常类型
    @ExceptionHandler(value = Throwable.class)
    public R handleException(Throwable throwable){

        return R.error(BizCodeEnume.UNKNOWN_EXCEPTION.getCode(),BizCodeEnume.UNKNOWN_EXCEPTION.getMsg());
    }
}
```









#### 软件搭建

1 虚拟机 

VirtualBox: https://download.virtualbox.org/virtualbox/6.0.10/VirtualBox-6.0.10-132072-Win.exe

2 Vagrant 

https://releases.hashicorp.com/vagrant/2.2.5/vagrant_2.2.5_x86_64.msi

 Vagrant 镜像仓库 https://app.vagrantup.com/boxes/search

3 安装好两个软件使用Vagrant给虚拟机创建镜像

![image-20210117104711356](G:\note\image\image-20210117104711356.png)

4 创建虚拟机

```
Vagrant init centos/7 //名字和镜像里一样可以创建一个Vagrantfile文件
```

![image-20210117105758949](G:\note\image\image-20210117105758949.png)

5 使用vagrant up 下载镜像和开启虚拟机

```
vagrant up //确保当前位置下有file文件
```

更改磁盘大小

1 翻墙安装插件    

```
vagrant plugin install vagrant-disksize
```

![image-20210123125902808](G:\note\image\image-20210123125902808.png)

6 ![image-20210117110759459](G:\note\image\image-20210117110759459.png)

```
vagrant ssh  //连接虚拟机 
```

7给虚拟机指定ip

先查看网段为56

![image-20210117111624077](G:\note\image\image-20210117111624077.png)

![image-20210117111700033](G:\note\image\image-20210117111700033.png)

之后使用  vagrant reload  重启虚拟机

8 vagrant ssh 连接虚拟机  ip addr 查看ip 

![image-20210117111848191](G:\note\image\image-20210117111848191.png)

#### 安装docker

镜像容器

仓库地址 https://hub.docker.com/

安装步骤 https://docs.docker.com/engine/install/centos/

1 卸载之前的docker

```
sudo yum remove docker \
                  docker-client \
                  docker-client-latest \
                  docker-common \
                  docker-latest \
                  docker-latest-logrotate \
                  docker-logrotate \
                  docker-engine
```

2 设置地址

````
$ sudo yum install -y yum-utils

$ sudo yum-config-manager \
    --add-repo \
    https://download.docker.com/linux/centos/docker-ce.repo
````

3 安装

```
sudo yum install docker-ce docker-ce-cli containerd.io
```

报错 

```
requires containerd.io ＞= 1.4.1, but none of the providers can be installed
解决
dnf install https://download.docker.com/linux/centos/8/x86_64/stable/Packages/containerd.io-1.4.3-3.1.el8.x86_64.rpm
```



4 启动docker(先关闭防火墙)

```
sudo systemctl start docker
sudo systemctl enable docker
```

5 配置镜像加速(需要先登录阿里云)

https://cr.console.aliyun.com/cn-shanghai/instances/mirrors

```
sudo mkdir -p /etc/docker
sudo tee /etc/docker/daemon.json <<-'EOF'
{
  "registry-mirrors": ["https://64dnk2wc.mirror.aliyuncs.com"]
}
EOF
sudo systemctl daemon-reload //重启docker后台线程
sudo systemctl restart docker
```

#### docker安装mysql

1 镜像仓库搜索mysql 根据tag选择

![image-20210117113939391](G:\note\image\image-20210117113939391.png)

2 sudo docker pull mysql:5.7  //冒号后跟tag

```
docker images 查看本地所有镜像
docker search 镜像名称 搜索镜像
docker pull 镜像名称 拉取镜像

docker rmi -f 镜像名称 删除镜像

```

容器 ：运行镜像就成了一个容器

```
docker run -i 镜像名称:标签 运行容器（默认是前台运行）
docker ps 查看运行的容器
docker ps -a 查询所有容器
docker exec -it mysql(容器名字或id) /bin/bash 进入容器内部

docker start 容器ID 
docker stop 容器ID

常用的参数：
-i：运行容器
-d：后台守方式运行（守护式）
--name：给容器添加名称
-p：3306:3306 端口映射
-v：挂载目录
```

3 运行mysql 挂载容器里的文件

![image-20210117121906838](G:\note\image\image-20210117121906838.png)

```
sudo docker run -p 3306:3306 --name mysql \
-v /mydata/mysql/log:/var/log/mysql \
-v /mydata/mysql/data:/var/lib/mysql \
-v /mydata/mysql/conf:/etc/mysql \
-e MYSQL_ROOT_PASSWORD=root \
-d mysql:5.7
端口映射
挂载日志
挂载配合
挂载文件夹


设置启动密码
docker update mysql(镜像名字) --restart=always  //启动docker时自动启动容器

如果容器启动出错
docker logs 容器ID  可以查看原因
```

运行成功之后可以使用docker ps查看运行的容器

使用navicat连接数据库查看

![image-20210117121655004](G:\note\image\image-20210117121655004.png)

4 更改mysql的配置文件

```
cd  /mydata/mysql/conf 进入到mysql本地挂载的配置文件 初次为空
vi my.cnf 创建配置文件
加入以下配置
[client]
default-character-set=utf8
[mysql]
default-character-set=utf8
[mysqld]
init_connect='SET collation_connection = utf8_unicode_ci'
init_connect='SET NAMES utf8'
character-set-server=utf8
collation-server=utf8_unicode_ci
skip-character-set-client-handshake
skip-name-resolve
```

4 docker restart mysql  重启mysql ![image-20210117123950942](G:\note\image\image-20210117123950942.png)

5 docker exec -it mysql /bin/bash  发现有my.cnf就配置成功了

#### docker 安装redis

1 docker pull redis //默认下载最新的

2 挂载文件

```
先创建配置文件
mkdir -p /mydata/redis/conf
touch /mydata/redis/conf/redis.conf
运行挂载目录
sudo docker run -p 6379:6379 --name redis -v /mydata/redis/data:/data -v /mydata/redis/conf/redis.conf:/etc/redis/redis.conf -d redis redis-server /etc/redis/redis.conf
```

 错误

```
如果已经运行这个名字的容器再次运行时会出错
docker: Error response from daemon: Conflict. The container name "/redis" is already in use by container "b7f72761bbcb95327d7b4be82c2cd961151dacf37280d80f8c1f8404ed8c4200". You have to remove (or rename) that container to be able to reuse that name.
解决
使用docker ps -a 查看运行的容器id
docker rm ID   删除容器
```

3 连接redis

![image-20210117130246767](G:\note\image\image-20210117130246767.png)

```
docker exec -it redis redis-cli
```

4 持久化  

此时redis的数据存在内存中 重启redis就没有了

进入映射的配置文件

![image-20210117130616218](G:\note\image\image-20210117130616218.png)

添加内容

![image-20210117130538769](G:\note\image\image-20210117130538769.png)

redis中存入值  set a bb

重启redis      docker restart redis

连接redis      docker exec -it redis redis-cli

获取值 依然可以获取的到

可以安装redis的可视化工具  redis desktop manager

开发环境

1 maven镜像该阿里云

```xml
 <mirrors>
    <mirror>
     <id>aliyunmaven</id>
     <mirrorOf>central</mirrorOf>
     <name>阿里云公共仓库</name>
     <url>https://maven.aliyun.com/repository/central</url>
    </mirror>
    <mirror>
      <id>repo1</id>
      <mirrorOf>central</mirrorOf>
      <name>central repo</name>
      <url>http://repo1.maven.org/maven2/</url>
    </mirror>
    <mirror>
     <id>aliyunmaven</id>
     <mirrorOf>apache snapshots</mirrorOf>
     <name>阿里云阿帕奇仓库</name>
     <url>https://maven.aliyun.com/repository/apache-snapshots</url>
    </mirror>
  </mirrors>
  <proxies/>
  <activeProfiles/>
  <profiles>
    <profile>  
        <repositories>
           <repository>
                <id>aliyunmaven</id>
                <name>aliyunmaven</name>
                <url>https://maven.aliyun.com/repository/public</url>
                <layout>default</layout>
                <releases>
                        <enabled>true</enabled>
                </releases>
                <snapshots>
                        <enabled>true</enabled>
                </snapshots>
            </repository>
            <repository>
                <id>MavenCentral</id>
                <url>http://repo1.maven.org/maven2/</url>
            </repository>
            <repository>
                <id>aliyunmavenApache</id>
                <url>https://maven.aliyun.com/repository/apache-snapshots</url>
            </repository>
        </repositories>             
     </profile>
  </profiles>
```

2 jdk改为1.8

```xml
<profile>   
    <id>jdk-1.8</id>   
     <activation>   
          <activeByDefault>true</activeByDefault>   
          <jdk>1.8</jdk>   
      </activation>   
    <properties>   
    <maven.compiler.source>1.8</maven.compiler.source>   
    <maven.compiler.target>1.8</maven.compiler.target>   
    <maven.compiler.compilerVersion>1.8</maven.compiler.compilerVersion>   
    </properties>
</profile>
```

3 vscode 安装插件

![image-20210117135031103](G:\note\image\image-20210117135031103.png)

4 github上创建项目 clone下来用IDEA打开

1 创建微服务项目

商品服务 仓库服务 订单服务 优惠券服务 用户服务

1 每个服务选择web openfeign

2 包名 com.atguigu.gulimall.xx(product/order/ware/coupon/member)

3 模块名 gulimall-coupon

![image-20210117141911687](G:\note\image\image-20210117141911687.png)

选择依赖

![image-20210117142451633](G:\note\image\image-20210117142451633.png)

![image-20210117142527644](G:\note\image\image-20210117142527644.png)

#### 递归查询菜单

```java
    public List<CategoryEntity> listWithTree(){
        //1 查出所有分类
        List<CategoryEntity> enetities = baseMapper.select(null);
        //根据parentId为0找出所有的一级分类
        List<CategoryEntity> level1 = entities.stream().filter(categoryEntity->{
            return categoryEntity.getParentCid() == 0;
        }).map((menu)->{
            menu.setChidren(null);
            return menu;
        }).sorted((menu1,menu2)->{
            return (menu1.getSort()==null?0:menu1.getSort()) -(menu2.getSort()==null?0:menu2.getSort())
        }).Collect(Collectors.toList());
        return level1;

        getChildrens(level1,enetities);
    }

    private List<CategoryEntity> getChildrens(CategoryEntity root,List<CategoryEntity> allList){
        //根据parentId = getCatId
        List<CategoryEntity> children = allList.stream.filter(categoryEntity - >{
            return categoryEntity.getParentId() == root.getCatId;
        }).map(categoryEntity -> {
            // 子分类再次传入该方法 插叙他的子分类
            categoryEntity.setChildren(getChildrens(categoryEntity,allList));
            return categoryEntity;
        }).collect(Collectors.toList());
        return children;
    }
```



#### 创建数据库

![image-20210117164653885](G:\note\image\image-20210117164653885.png)

每个选择一下配置

![image-20210117164526194](G:\note\image\image-20210117164526194.png)

用对应的sql文件在库中创建相应的表

![image-20210117165059179](C:\Users\gg\AppData\Roaming\Typora\typora-user-images\image-20210117165059179.png)

#### 整合项目

https://gitee.com/renrenio 删除其中的.git文件

1 下载人人开源 fast(前端) fast-vue(后端)

2 更改其中的数据库

3 加载全部依赖   启动项目

![image-20210117194249987](G:\note\image\image-20210117194249987.png)

4 下载代码生成器工程 https://gitee.com/renrenio/renren-generator

1修改数据库配置

![image-20210117195044400](G:\note\image\image-20210117195044400.png)

2 修改代码生成器配置

![image-20210117194707606](C:\Users\gg\AppData\Roaming\Typora\typora-user-images\image-20210117194707606.png)

#### SpringCloudAlibaba

#### 服务注册

![image-20210117221638730](G:\note\image\image-20210117221638730.png)

1 安装nacos 

2 每个微服务注册进nacos

1 公共模块引入依赖

```xml
<dependency>
    <groupId>com.alibaba.cloud</groupId>
    <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
</dependency>
```

2 添加配置

```
cloud:
    nacos:
      discovery:
        server-addr: localhost:8848 #配置Nacos地址
  application:
    name: gulimall-order  //每个服务写自己的名字
```

3 主启动类添加   @EnableDiscoveryClient

服务间调用

1 安装依赖

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-openfeign</artifactId>
</dependency>
```

2 主启动类添加注解 

```java
@SpringBootApplication
@EnableDiscoveryClient
@EnableFeignClients(basePackages = "com.atguigu.gulimall.member.feign")
public class GulimallMemberApplication {

	public static void main(String[] args) {
		SpringApplication.run(GulimallMemberApplication.class, args);
	}

}
```

3 编写接口

```java
@Service
@FeignClient("gulimall-coupon") //注册中心服务的名称
public interface CouponFeignService {

    @GetMapping("coupon/coupon/test") //调用接口的全部路径
    public R testMessage();
}
```

4 controller调用

```java
@Resource
private CouponFeignService couponFeignService;

@GetMapping("testFeign")
public R get(){
    R r = couponFeignService.testMessage();
    return r;
}
```

递归获取树形列表

```java
public List<CategoryEntity> listWithTree() {
    //查出所有分类
    List<CategoryEntity> entities = baseMapper.selectList(null);
    //获取所有的一级分类
    List<CategoryEntity> collect = entities.stream()
        .filter((categoryEntity -> categoryEntity.getParentCid() == 0))
        .map((menu)->{menu.setChildren(getChildrens(menu,entities)); return menu;})
        .sorted((menu1,menu2)->{
            return (menu1.getSort() == null? 0 :menu1.getSort()) - (menu2.getSort() == null? 0 :menu2.getSort());
        })
        .collect(Collectors.toList());
    //组装树形分类
    return collect;
}
//
private List<CategoryEntity> getChildrens(CategoryEntity root,List<CategoryEntity> all){
    List<CategoryEntity> children = all.stream().filter(categoryEntity ->{
        return categoryEntity.getParentCid() == root.getCatId();
    }).map(categoryEntity->{
        categoryEntity.setChildren(getChildrens(categoryEntity,all));
        return categoryEntity;
    }).sorted((menu1,menu2)->{
        return (menu1.getSort() == null? 0 :menu1.getSort()) - (menu2.getSort() == null? 0 :menu2.getSort());
    }).collect(Collectors.toList());
    return children;
}
```



解决跨域

![image-20210118214052391](G:\note\image\image-20210118214052391.png)



![image-20210118214245660](G:\note\image\image-20210118214245660.png)

#### 网关解决跨域

```java
@Configuration
public class GulimallCorsConfig{
    @Bean
    public CorsWebFilter corsWebFilter(){
        UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource();
        CorsConfiguration corsConfiguration = new CorsConfiguration();
        corsConfiguration.addAllowedHeader("*");
        corsConfiguration.addAllowedMethod("*");
        corsConfiguration.addAllowedOrigin("*");
        corsConfiguration.setAllowCredentials(true);

        source.registerCorsConfiguration("/**",corsConfiguration);
        return new CorsWebFilter(source);
    }
}
```

枚举常量

1 新建类

```java
package com.atguigu.common.constant;


public class ProductConstant {
    public enum AttrEnum{
        ATTR_TYPE_BASE(1,"基本属性"),ATTR_TYPE_SALE(0,"销售属性");
        private int code;
        private String msg;

        AttrEnum(int code,String msg){
            this.code = code;
            this.msg = msg;
        }

        public int getCode(){
            return code;
        }

        public String getMsg(){
            return msg;
        }
    }
}

```

2 使用方法

```java
QueryWrapper<AttrEntity> queryWrapper= new QueryWrapper<AttrEntity>()
    .eq("attr_type","base".equalsIgnoreCase(type)? ProductConstant.AttrEnum.ATTR_TYPE_BASE.getCode():ProductConstant.AttrEnum.ATTR_TYPE_SALE.getCode());
```

#### Elasticsearch

快速检索

![image-20210121113006306](G:\note\image\image-20210121113006306.png)

###### 倒排索引

![image-20210121113026366](G:\note\image\image-20210121113026366.png)

###### docker中安装 Elasticsearch

1 安装

```java
docker pull elasticsearch:7.4.2  //下载镜像
docker pull kibana:7.4.2  //可视化检索

挂载配置
1创建挂载目录
mkdir -p /mydata/elasticsearch/config
mkdir -p /mydata/elasticsearch/data
2 开启远程访问
/mydata/elasticsearch/config/elasticsearch.yml
network.host: 0.0.0.0  #改为0.0.0.0对外开放，如对特定ip开放则改为指定ip
http.port: 9200      #可更改端口不为9200
echo "http.host: 0.0.0.0">>/mydata/elasticsearch/config/elasticsearch.yml

3 运行

docker run --name elasticsearch -p 9200:9200 -p 9300:9300 \
-e "discovery.type=single-node" \
-e ES_JAVA_OPTS="-Xms64m -Xmx1024m" \
-v /mydata/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \
-v /mydata/elasticsearch/data:/usr/share/elasticsearch/data \
-v /mydata/elasticsearch/plugins:/usr/share/elasticsearch/plugins \
-d elasticsearch:7.4.2

更改权限
chmod -R 777 /mydata/elasticsearch  更改所有人都可读写执行
docker logs elasticsearch //查看运行日志


4 Kibana
docker run --name kibana -e ELASTICSEARCH_HOSTS=http://192.168.111.156:9200/ -p 5601:5601 -d kibana:7.4.2
```

更改当前索引修改数据

```
PUT http://127.0.0.1:9200/索引名称/_settings
{
"index.blocks.read_only_allow_delete": null
}
```



#### 初步检索

1 _cat

```properties
 GET/_cat/nodes:  查看所有节点
 GET/_cat/health: 查看健康状况
  GET/_cat/master: 查看主节点
   GET/_cat/indices: 查看所有索引
```

2 保存数据

```
http:ip:9200/索引/类型/数据名
发送请求

put请求保存
http:192.168.56.10:9200/customer/externam/1  //再次发送 如果数据名已经有了就位update
{
  "name":"小明"
}


post请求
不带id就是新增随机产生id  再次发送 如果数据名已经有了就位update
http:192.168.56.10:9200/customer/externam
http:192.168.56.10:9200/customer/externam/1if_seq_no=1&if_primary_term=1 //带乐观锁修改
{
  "name":"小明"
}
```

3 查询数据

```
http:ip:9200/索引/类型/数据名   get请求

{
  "_index":"customer"  //索引
  "_type":"external"  // 类型
  "_id":"1"           //数据标识
  "_version":2,       //版本号
  "_seq_no":1,        //乐观锁
  "_primary_term":1,  //主分片重新分配
  "found":true,       //是否有数据
  "_source":{         //数据内容
    "name":"小明"  
  }
}
```

4 更新数据

```
POST customer/external/1/_update   //会对比原来数据  如果数据一样 就不改变数 version不变
{
    "doc":{
      "name":"小明",
      "age":20
    }
}
或者带Id标识的   put post请求
```

5 查询

```
DELETE customer/external/1  //删除数据
DELETE customer//删除索引
```

#### kibana

http://192.168.111.133:5601

![image-20210121165641095](G:\note\image\image-20210121165641095.png)

```
POST /customer/externam/_bulk
{"index":{"_id":"1"}}
{"name":"这是第一个"}
{"index":{"_id":"2"}}
{"name":"这是第2个"}
{"index":{"_id":"3"}}
{"name":"这是第3个"}

POST _bulk
{"delete":{"_index":"website","_type":"blog","_id":"123"}}
{"create":{"_index":"website","_type":"blog","_id":"123"}}  //如果和原来的数据一样 版本号不会添加 序列号也不加
{"title":"MY first blog post"}
{"index":{"_index":"website","_type":"blog","_id":"123"}}  //保存
{"title":"My second blog post"}
{"update":{"_index":"website","_type":"blog","_id":"123"}}
{"doc":{"title":"My update blog post"}}
```

测试数据  https://github.com/elastic/elasticsearch/blob/master/docs/src/test/resources/accounts.json

保存测试数据

```
POST /bank/account/_bulk
{"index":{"_id":"1"}}
```

#### 进阶检索

基本检索

1 条件检索 条件封装在uri中

![image-20210121173004371](G:\note\image\image-20210121173004371.png)

```
GET bank/_search?q=*&sort=account_number:asc
```

2 条件在请求体里 Query DSL

```properties
GEt bank/_search
{
  "query":{"match_all": {}},  //查询全部条件
  "sort":[
    {"account_number":"asc"}, //升序
    {"balance":"desc"}  //降序
    ]
}
```

3 查询全部范围

```properties
GET bank/_search
{
  "query": { "match_all": {} },  //查询全部条件
  "sort": [
    {
      "balance": {
        "order": "asc"   // balance字段 升序
      }
    }
  ],
  "from": 0,    //从0 到5 五条数据
  "size": 5,
  "_source": ["balance","firstname","age"]  //自定义值返回部分字段
}



```

#### match查询 

```
GET bank/_search
{
  "query": {"match": {
    "address": "Kings" //进行分词匹配 匹配address中含有Kings这个词
  }}
}
```

5 完整短语匹配match_phrase

```
GET bank/_search
{
  "query": {
    "match_phrase": {
      "address": "mill lan",  //只会匹配包含 mill lan 如果match会进行分词匹配 包含两个单词都会返回
      address.keyword": "mill lan"  //值定于 不是包含mill lan
    }
  }
}
```

6  multi_match 多字段匹配

```
GET bank/_search
{
 "query":{
    "multi_match":{
      "query":"mill movice",  //分词检索
      "fields":["state","address"]  //两个字段里包含mill的都返回
    }
 }
}
```

6 组合查询 query->bool    must must_not  

```

GET bank/_search
{
  "query": {
    "bool": {  //组合查询
      "must": [
        {"match": {
          "gender": "M"
        }},
        {
          "match": {
            "address": "mill"
          }
        }
      ],
      "must_not": [
        {"match": {
          "age": "38"
        }}
      ],
      "should": [
        {"match": {
          "lastname": "Wallace"
        }}
      ],
      "filter": {  //与match功能相似 但是匹配到不贡献得分
        "range": {
          "age": {
            "gte": 10,
            "lte": 30
          }
        }
      }
    }
  }
}
```

7 term //推荐查找精确值

```
GET bank/_search
{
  "query": {
    "term": {
      "age": {
        "value": 20   //字段值等于20 并不是包含
      }
    }
  }
}
```

8 内部属性查询

```
类似于对象又有对象
{
  name:"小明",
  info:{
    address:"河南"
  }
}
```



![image-20210328083338976](G:\note\image\image-20210328083338976.png)

```
GET product/_search

{
  "query": {
    "nested": {
      "path": "attrs",   //内部属性对象的名
      "query": {
        "bool": {
          "must": [
            {
              "term": {
                "attrs.attrId //内部值得字段名
                  "value": "15"
                }
              }
            },
            {
            "terms":{
              "attrs.attrValue":[
                "Adams",
                "Hutchinson"
                ]
            }
            }
          ]
        }
      }
    }
  }
}
```

###### 嵌入查询

![image-20210516102645552](G:\note\image\image-20210516102645552.png)

#### 聚合统计

1 所有人聚合统计

```
GET bank/_search
{
  "query": {
    "match": {
      "address": "mill"
    }
  },
  "aggs": {
    "ageAgg": {   //自定义聚合名字
      "terms": {   //条件
        "field": "age", //聚合的字段
        "size":10  //聚合可能有许多种 从中取出10中
      }
    },
   "ageAvg": {   
        "avg": {  // 所有人求平均值
          "field": "balance"
        }
      }
  }
}
```

2 查出条件内 在进行聚合统计

```
GET bank/_search
{
  "query": {
    "match_all": {}
  },
  "aggs": {
    "ageAgg": {
      "terms": {
        "field": "age",
        "size": 10
      },
      "aggs":{  //每个age分组内在进行 求平均值
        "ageAvg":{
          "avg": {
            "field": "balance"
          }
        }
      }
    }
  }
}

结果分析
"aggregations" : {
    "ageAgg" : {
      "doc_count_error_upper_bound" : 0,
      "sum_other_doc_count" : 463,
      "buckets" : [
        {
          "key" : 31,  //age =31的有 61人
          "doc_count" : 61,
          "ageAvg" : {
            "value" : 28312.918032786885  //平均值为
          }
        },
        {
          "key" : 39,
          "doc_count" : 60,
          "ageAvg" : {
            "value" : 25269.583333333332
          }
        },
        {
          "key" : 26,
          "doc_count" : 59,
          "ageAvg" : {
            "value" : 23194.813559322032
          }
        }
      ]
    }
  }

```

4 根据年龄聚合

```properties
GET bank/_search
{
  "query": {"match_all": {}},
  "aggs": {
    "ageAgg": { 根据年龄聚合
      "terms": {
        "field": "age",
        "size": 10
      },
      "aggs": {
        "genderAgg": { //再根据性别聚合
          "terms": {
            "field": "gender.keyword",
            "size": 10
          },
          "aggs": {  // 再查出平均值
            "avgAgg": {
              "avg": {
                "field": "balance"
              }
            }
          }
        }
      }
    }
  }
}

```

###### mapping 存储的数据类型

```
GET /bank/_mapping
```

创建映射

```
# 创建数据前先指定类型
PUT /my_index
{
  "mappings": {
    "properties": {
      "age":{"type": "integer"},
      "email":{"type": "keyword"},
      "name":{"type": "text"}
    }
  }
}
获取映射
PUT /my_index/_mapping

添加字段的数据类型
PUT /my_index/_mapping
{
  "properties":{
    "employee_id":{
      "type":"keyword", 
      "index":false
    }
  }
}
```

修改mapping  已经存在的字段不能修改类。只能做数据迁移

1 新建mapping

```
PUT newbank
{
  "mappings": {
    "properties": {
          "account_number" : {
          "type" : "integer"
        },
        "address" : {
          "type" : "text"
        },
        "age" : {
          "type" : "integer"
        },
        "balance" : {
          "type" : "integer"
        },
        "city" : {
          "type" : "text"
        },
        "email" : {
          "type" : "keyword"
        },
        "employer" : {
          "type" : "keyword"
        },
        "firstname" : {
          "type" : "text"
        },
        "gender" : {
          "type" : "keyword"
        },
        "lastname" : {
          "type" : "text"
        },
        "state" : {
          "type" : "keyword"
        }
    }
  }
}
```

2 数据迁移

```
POST _reindex
{
  "source": {
    "index": "bank",
    "type": "account"
  },
  "dest": {
    "index": "newbank"
  }
}
```

###### 分词器  

将我们的一句话拆分成多个部分，

```
POST _analyze
{
  "analyzer": "standard",
  "text": "尚硅谷电商项目"
}

结果
{
  "tokens" : [
    {
      "token" : "尚",
      "start_offset" : 0,
      "end_offset" : 1,
      "type" : "<IDEOGRAPHIC>",
      "position" : 0
    },
    {
      "token" : "硅",
      "start_offset" : 1,
      "end_offset" : 2,
      "type" : "<IDEOGRAPHIC>",
      "position" : 1
    },
    {
      "token" : "谷",
      "start_offset" : 2,
      "end_offset" : 3,
      "type" : "<IDEOGRAPHIC>",
      "position" : 2
    },
    {
      "token" : "电",
      "start_offset" : 3,
      "end_offset" : 4,
      "type" : "<IDEOGRAPHIC>",
      "position" : 3
    },
    {
      "token" : "商",
      "start_offset" : 4,
      "end_offset" : 5,
      "type" : "<IDEOGRAPHIC>",
      "position" : 4
    },
    {
      "token" : "项",
      "start_offset" : 5,
      "end_offset" : 6,
      "type" : "<IDEOGRAPHIC>",
      "position" : 5
    },
    {
      "token" : "目",
      "start_offset" : 6,
      "end_offset" : 7,
      "type" : "<IDEOGRAPHIC>",
      "position" : 6
    }
  ]
}

```

###### ik分词器

1 下载分词器

```
https://github.com/medcl/elasticsearch-analysis-ik
```

2 在映射的

```
把下载的压缩包解压到下面目录启动
/mydata/elasticsearch/plugins/ik 重启es
```

进入到elasticsearch容器内部 查看ik分词器  是否已经安装了

![image-20210515184647194](G:\note\image\image-20210515184647194.png)

![image-20210515184416295](G:\note\image\image-20210515184416295.png)

3 使用

ik_smart

```
POST _analyze
{
  "analyzer": "ik_smart",
  "text": "尚硅谷电商项目"
}

只能分词
{
  "tokens" : [
    {
      "token" : "尚",
      "start_offset" : 0,
      "end_offset" : 1,
      "type" : "CN_CHAR",
      "position" : 0
    },
    {
      "token" : "硅谷",
      "start_offset" : 1,
      "end_offset" : 3,
      "type" : "CN_WORD",
      "position" : 1
    },
    {
      "token" : "电",
      "start_offset" : 3,
      "end_offset" : 4,
      "type" : "CN_CHAR",
      "position" : 2
    },
    {
      "token" : "商",
      "start_offset" : 4,
      "end_offset" : 5,
      "type" : "CN_CHAR",
      "position" : 3
    },
    {
      "token" : "项目",
      "start_offset" : 5,
      "end_offset" : 7,
      "type" : "CN_WORD",
      "position" : 4
    }
  ]
}
```

ik_max_word

```
POST _analyze
{
  "analyzer": "ik_max_word",
  "text": "我是中国人"
}

{
  "tokens" : [
    {
      "token" : "我",
      "start_offset" : 0,
      "end_offset" : 1,
      "type" : "CN_CHAR",
      "position" : 0
    },
    {
      "token" : "是",
      "start_offset" : 1,
      "end_offset" : 2,
      "type" : "CN_CHAR",
      "position" : 1
    },
    {
      "token" : "中国人",
      "start_offset" : 2,
      "end_offset" : 5,
      "type" : "CN_WORD",
      "position" : 2
    },
    {
      "token" : "中国",
      "start_offset" : 2,
      "end_offset" : 4,
      "type" : "CN_WORD",
      "position" : 3
    },
    {
      "token" : "国人",
      "start_offset" : 3,
      "end_offset" : 5,
      "type" : "CN_WORD",
      "position" : 4
    }
  ]
}

```

###### 自定义分词库

###### 安装nginx

![image-20210121231100867](G:\note\image\image-20210121231100867.png)

 把分词库放到nginx里 让ik分词器 去请求nginx 获取最新分词库

1 拉取nginx镜像

```
docker pull nginx
```

2 运行

```
docker run --name nginx -p 80:80 -d nginx:1.10
```

3 复制配置文件

![image-20210121230845420](G:\note\image\image-20210121230845420.png)

```
docker container cp nginx:/etc/nginx .
```

4 运行nginx挂载文件

```
docker run --name nginx -p 80:80 \
-v /mydata/nginx/html:/usr/share/nginx/html \
-v /mydata/nginx/logs:/var/log/nginx \
-v /mydata/nginx/conf:/etc/nginx \
-d nginx:1.10
```

5 在挂载的nginx里新建 /html/es/fenci.txt   http://192.168.111.133/es/fenci.txt

6 修改ik分词器的远程词库

![image-20210121232931073](G:\note\image\image-20210121232931073.png)

文件 IKAnalyzer.cfg.xml 

![image-20210121232901927](G:\note\image\image-20210121232901927.png)

###### java操作elastic

1 创建gulimall-search微服务

2 引入依赖

```
<dependency>
    <groupId>org.elasticsearch.client</groupId>
    <artifactId>elasticsearch-rest-high-level-client</artifactId>
    <version>7.4.2</version>
</dependency>
```

查看

第一

![image-20210122000608194](G:\note\image\image-20210122000608194.png)

第二

![image-20210122000625142](G:\note\image\image-20210122000625142.png)

第三

![image-20210122000655347](G:\note\image\image-20210122000655347.png)

禁用springboot自己6.8.5版本的

![image-20210122000546262](G:\note\image\image-20210122000546262.png)

3 创建配置类

```java
@Configuration
public class GulimallElasticSearchConfig {

    public RestHighLevelClient esRestClient(){
        RestClientBuilder builder = RestClient.builder(new HttpHost("192.168.111.133", 9200, "http"));
        RestHighLevelClient client = new RestHighLevelClient(builder);
        return client;
    }
}
```

###### 复杂检索

根据查询的结果生成实体类对象

```java
@Data
	@ToString
	public static class Account{
			private int account_number;

			private int balance;

			private String firstname;

			private String lastname;

			private int age;

			private String gender;

			private String address;

			private String employer;

			private String email;

			private String city;

			private String state;

	}
```

```java
//复杂检索
	@Test
	public void searchData() throws IOException {
		// 1创建检索对象
		SearchRequest searchRequest = new SearchRequest();
		// 拼装检索条件
		searchRequest.indices("bank"); //索引
		// 指定DSL条件
		// 检索对象
		SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();
//		sourceBuilder.query();
//		sourceBuilder.from();
//		sourceBuilder.size();
//		sourceBuilder.aggregation();
		//query检索
		sourceBuilder.query(QueryBuilders.matchQuery("address","mill"));


		// 2 聚合
		//1 按年龄分配聚合
		TermsAggregationBuilder ageAgg = AggregationBuilders.terms("ageAgg").field("age").size(10);
		sourceBuilder.aggregation(ageAgg);

		//求平均值
		AvgAggregationBuilder avgAgg = AggregationBuilders.avg("avgAgg").field("balance");
		sourceBuilder.aggregation(avgAgg);

		searchRequest.source(sourceBuilder);

		// 2 执行检索
		SearchResponse searchResponse = client.search(searchRequest, GulimallElasticSearchConfig.COMMON_OPTIONS);

		//分析结果 searchResponse
		System.out.println("查询结果");
		System.out.println(searchResponse);

//		"hits": {
//			"total": {
//				"value": 4,
//						"relation": "eq"
//			},
//			"max_score": 5.4032025,
//					"hits": [{
//				"_index": "bank",
//						"_type": "account",
//						"_id": "970",
//						"_score": 5.4032025,
//						"_source": {
//					"account_number": 970,
//							"balance": 19648,
//							"firstname": "Forbes",
//							"lastname": "Wallace",
//							"age": 28,
//							"gender": "M",
//							"address": "990 Mill Road",
//							"employer": "Pheast",
//							"email": "forbeswallace@pheast.com",
//							"city": "Lopezo",
//							"state": "AK"
//				}
		SearchHits hits = searchResponse.getHits(); //外层hits对象
		System.out.println(hits);
		SearchHit[] hits1 = hits.getHits(); //内层 hits数组
		System.out.println(Arrays.toString(hits1));
		for(SearchHit hit:hits1){
			String id = hit.getId();
			String index = hit.getIndex();
//			Map<String, Object> sourceAsMap = hit.getSourceAsMap();
			String sourceAsString = hit.getSourceAsString();  //根据对象生成相应的实体类
			Account account = JSON.parseObject(sourceAsString, Account.class); //转为对象
			System.out.println(account);
		}

		// 获取聚合的结果
		Aggregations aggregations = searchResponse.getAggregations();

//		"lterms#ageAgg": {
//			"doc_count_error_upper_bound": 0,
//					"sum_other_doc_count": 0,
//		  "buckets": [{
//				"key": 38,
//						"doc_count": 2
//			}, {
//				"key": 28,
//						"doc_count": 1
//			}, {
//				"key": 32,
//						"doc_count": 1
//			}]
//		},
		Terms ageAgg1 = aggregations.get("ageAgg");//根据聚合的自定义名字获取聚合
		for (Terms.Bucket bucket : ageAgg1.getBuckets()) {
			String keyAsString = bucket.getKeyAsString();
			System.out.println("年龄:"+keyAsString);
		}
//		"avg#avgAgg": {
//			"value": 25208.0
//		}
		//前边的Avg根据结果"avg#avgAgg"选择
		Avg avgAgg1 = aggregations.get("avgAgg");
		double value = avgAgg1.getValue();
		System.out.println("平均值"+value);
	}
```

嵌入式属性 数组内部 属性 防止检索错误type nested

![image-20210123161424934](G:\note\image\image-20210123161424934.png)

###### search模块使用es

1 创建模块

2 引入依赖

```xml
<dependency>
    <groupId>org.elasticsearch.client</groupId>
    <artifactId>elasticsearch-rest-high-level-client</artifactId>
    <version>7.4.2</version>
</dependency>
```

3 修改springboot自带的el版本

```
	<properties>
		<java.version>1.8</java.version>
		覆盖springboot自带的版本
		<elasticsearch.version>7.4.2</elasticsearch.version>
	</properties>
```

4 添加配置类

```java
package com.atguigu.gulimall.search.config;

import org.apache.http.HttpHost;
import org.elasticsearch.client.RequestOptions;
import org.elasticsearch.client.RestClient;
import org.elasticsearch.client.RestClientBuilder;
import org.elasticsearch.client.RestHighLevelClient;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class GulimallElasticSearchConfig {

    public static final RequestOptions COMMON_OPTIONS;
    static {
        RequestOptions.Builder builder = RequestOptions.DEFAULT.toBuilder();
//        builder.addHeader("Authorization", "Bearer " + TOKEN);
//        builder.setHttpAsyncResponseConsumerFactory(
//                new HttpAsyncResponseConsumerFactory
//                        .HeapBufferedResponseConsumerFactory(30 * 1024 * 1024 * 1024));
        COMMON_OPTIONS = builder.build();
    }
    @Bean
    public RestHighLevelClient esRestClient(){
        RestClientBuilder builder = RestClient.builder(new HttpHost("192.168.111.133", 9200, "http"));
        RestHighLevelClient client = new RestHighLevelClient(builder);
        return client;
    }
}
```

 5 查询案例

```java
package com.atguigu.gulimall.search;

import com.alibaba.fastjson.JSON;
import com.atguigu.gulimall.search.config.GulimallElasticSearchConfig;
import lombok.Data;
import lombok.ToString;
import org.elasticsearch.action.get.GetRequest;
import org.elasticsearch.action.get.GetResponse;
import org.elasticsearch.action.index.IndexRequest;
import org.elasticsearch.action.index.IndexResponse;
import org.elasticsearch.action.search.SearchRequest;
import org.elasticsearch.action.search.SearchResponse;
import org.elasticsearch.action.update.UpdateRequest;
import org.elasticsearch.action.update.UpdateResponse;
import org.elasticsearch.client.RequestOptions;
import org.elasticsearch.client.RestHighLevelClient;
import org.elasticsearch.common.xcontent.XContentType;
import org.elasticsearch.index.query.QueryBuilders;
import org.elasticsearch.search.SearchHit;
import org.elasticsearch.search.SearchHits;
import org.elasticsearch.search.aggregations.Aggregation;
import org.elasticsearch.search.aggregations.AggregationBuilders;
import org.elasticsearch.search.aggregations.Aggregations;
import org.elasticsearch.search.aggregations.bucket.terms.Terms;
import org.elasticsearch.search.aggregations.bucket.terms.TermsAggregationBuilder;
import org.elasticsearch.search.aggregations.metrics.Avg;
import org.elasticsearch.search.aggregations.metrics.AvgAggregationBuilder;
import org.elasticsearch.search.builder.SearchSourceBuilder;
import org.junit.Test;
import org.junit.runner.RunWith;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.test.context.junit4.SpringRunner;

import javax.annotation.Resource;
import java.io.IOException;
import java.util.Arrays;
import java.util.HashMap;

@RunWith(SpringRunner.class)
@SpringBootTest
public class GulimallSearchApplicationTests {
	@Resource
    private RestHighLevelClient client;

	//复杂检索
	@Test
	public void searchData() throws IOException {
		// 1创建检索对象
		SearchRequest searchRequest = new SearchRequest();
		// 拼装检索条件
		searchRequest.indices("bank"); //索引
		// 指定DSL条件
		// 检索对象
		SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();
//		sourceBuilder.query();
//		sourceBuilder.from();
//		sourceBuilder.size();
//		sourceBuilder.aggregation();
		//query检索
		sourceBuilder.query(QueryBuilders.matchQuery("address","mill"));


		// 2 聚合
		//1 按年龄分配聚合
		TermsAggregationBuilder ageAgg = AggregationBuilders.terms("ageAgg").field("age").size(10);
		sourceBuilder.aggregation(ageAgg);

		//求平均值
		AvgAggregationBuilder avgAgg = AggregationBuilders.avg("avgAgg").field("balance");
		sourceBuilder.aggregation(avgAgg);

		searchRequest.source(sourceBuilder);

		// 2 执行检索
		SearchResponse searchResponse = client.search(searchRequest, GulimallElasticSearchConfig.COMMON_OPTIONS);

		//分析结果 searchResponse
		System.out.println("查询结果");
		System.out.println(searchResponse);

//		"hits": {
//			"total": {
//				"value": 4,
//						"relation": "eq"
//			},
//			"max_score": 5.4032025,
//					"hits": [{
//				"_index": "bank",
//						"_type": "account",
//						"_id": "970",
//						"_score": 5.4032025,
//						"_source": {
//					"account_number": 970,
//							"balance": 19648,
//							"firstname": "Forbes",
//							"lastname": "Wallace",
//							"age": 28,
//							"gender": "M",
//							"address": "990 Mill Road",
//							"employer": "Pheast",
//							"email": "forbeswallace@pheast.com",
//							"city": "Lopezo",
//							"state": "AK"
//				}
		SearchHits hits = searchResponse.getHits(); //外层hits对象
		System.out.println(hits);
		SearchHit[] hits1 = hits.getHits(); //内层 hits数组
		System.out.println(Arrays.toString(hits1));
		for(SearchHit hit:hits1){
			String id = hit.getId();
			String index = hit.getIndex();
//			Map<String, Object> sourceAsMap = hit.getSourceAsMap();
			String sourceAsString = hit.getSourceAsString();  //根据对象生成相应的实体类
			Account account = JSON.parseObject(sourceAsString, Account.class); //转为对象
			System.out.println(account);
		}

		// 获取聚合的结果
		Aggregations aggregations = searchResponse.getAggregations();

//		"lterms#ageAgg": {
//			"doc_count_error_upper_bound": 0,
//					"sum_other_doc_count": 0,
//		  "buckets": [{
//				"key": 38,
//						"doc_count": 2
//			}, {
//				"key": 28,
//						"doc_count": 1
//			}, {
//				"key": 32,
//						"doc_count": 1
//			}]
//		},
		Terms ageAgg1 = aggregations.get("ageAgg");//根据聚合的自定义名字获取聚合
		for (Terms.Bucket bucket : ageAgg1.getBuckets()) {
			String keyAsString = bucket.getKeyAsString();
			System.out.println("年龄:"+keyAsString);
		}
//		"avg#avgAgg": {
//			"value": 25208.0
//		}
		//前边的Avg根据结果"avg#avgAgg"选择
		Avg avgAgg1 = aggregations.get("avgAgg");
		double value = avgAgg1.getValue();
		System.out.println("平均值"+value);
	}
	@Data
	@ToString
	public static class Account{
			private int account_number;

			private int balance;

			private String firstname;

			private String lastname;

			private int age;

			private String gender;

			private String address;

			private String employer;

			private String email;

			private String city;

			private String state;

	}
	@Test
	public void contextLoads() {
		System.out.println(client);
	}
	//新增数据
	@Test
	public void indexData() throws IOException {
		IndexRequest indexRequest = new IndexRequest("users"); //数据index
		indexRequest.id("1"); //数据的id
		User user = new User(); //传递的数据类对象
		user.setAge(20);
		user.setName("小明");
		String jsonString = JSON.toJSONString(user); //转为json传递
		indexRequest.source(jsonString, XContentType.JSON);  //传递的json字符串和数据类型

		//执行操作
		IndexResponse index = client.index(indexRequest, GulimallElasticSearchConfig.COMMON_OPTIONS);

		//响应的数据
		System.out.println(index);
	}


	//获取数据
	@Test
	public void getData() throws IOException {      //索引     id
		GetRequest getRequest = new GetRequest("users", "1");
		GetResponse getResponse = client.get(getRequest, RequestOptions.DEFAULT);
		// {"_index":"users","_type":"_doc","_id":"1","_version":2,"_seq_no":1,"_primary_term":1,"found":true,"_source":{"age":20,"name":"小明"}}
		System.out.println(getResponse.getSource());  //  {name=小明, age=20}
		System.out.println(getResponse.getIndex());  // users
		System.out.println(getResponse.getId());   // 1
	}


	//更新数据
	@Test
	public void updateData() throws IOException {
		UpdateRequest updateRequest = new UpdateRequest("users","1");
		User user = new User(); //传递的数据类对象
		user.setAge(100);
		user.setName("小明666");
//		String jsonString = JSON.toJSONString(user); //转为json传递
		HashMap<String, String> userashMap = new HashMap<>();
		userashMap.put("age","200");
		userashMap.put("user","user");
		updateRequest.doc(userashMap);
		//执行操作
		UpdateResponse update = client.update(updateRequest, GulimallElasticSearchConfig.COMMON_OPTIONS);

		//响应的数据
		System.out.println(update);
	}
	@Data
	class User{
		private String name;
		private Integer age;
	}
}

```



#### R类根据需要返回对应的结果

```java
public R setData(Object data){
		put("data",data);
		return this;
	}
//把JSON转为我们需要的数据类型
public <T> T getData(TypeReference<T> typeReference){

Object data = get("data"); //获取的是map
String s = JSON.toJSONString(data); //map转json
T t=	JSON.parseObject(s,typeReference);  //json转需要的数据类型
return t;
}
```

```java
R r = wareFeignService.getSkusHasStock(skuIdList);
               //需要返回的数据类型
TypeReference<List<SkuHasStockVo>> typeReference = new TypeReference<List<SkuHasStockVo>>() {
};
            stockMap= r.getData(typeReference).stream().collect(Collectors.toMap(SkuHasStockVo::getSkuId, item -> item.getHasStock()));
```



#### 性能监控

![image-20210515202352587](G:\note\image\image-20210515202352587.png)

###### 压力测试

1 添加线程组

![image-20210206110757553](G:\note\image\image-20210206110757553.png)

2 添加请求类型

![image-20210515203257532](G:\note\image\image-20210515203257532.png)

3 添加报告图

![image-20210206114607533](C:\Users\gg\AppData\Roaming\Typora\typora-user-images\image-20210206114607533.png)

###### JVM内存优化

1 jvm内存模型

![image-20210206121137315](G:\note\image\image-20210206121137315.png)

![image-20210206121152515](G:\note\image\image-20210206121152515.png)

垃圾回收机制

![image-20210206122235817](G:\note\image\image-20210206122235817.png)

jconsole与jvisualvm

jdk的两个小工具，通过命令行启动，可监控本地和远程应用。

![image-20210206122809081](G:\note\image\image-20210206122809081.png)

![image-20210206123315302](G:\note\image\image-20210206123315302.png)

Nginx动静分类

1 nginx创建静态资源文件夹

![image-20210207080515683](G:\note\image\image-20210207080515683.png)

2 nginx配置转发

```java
location /static {
    root   /usr/share/nginx/html/;
}
```

3 页面资源请求路径为static开头

```html
<link rel="stylesheet" href="/static/index/css/swiper-3.4.2.min.css">
  <link rel="stylesheet" href="/static/index/css/GL.css">
  <script src="/static/index/js/jquery-3.1.1.min.js" type="text/javascript" charset="utf-8"></script>

  <script src="/static/index/js/swiper-3.4.2.jquery.min.js" type="text/javascript" charset="utf-8"></script>

  <script src="/static/index/js/swiper-3.4.2.min.js"></script>
```

#### 整合redis

1 引入redis的stater

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-redis</artifactId>
</dependency>

```

2 配置redis的ip地址

```
spring:
   redis:
      host: 192.168.56.10
```

3 使用springboot自动配置好的StringRedisTemplater来操作redis

![image-20210326080104724](G:\note\image\image-20210326080104724.png)

```java
@Autowired
    StringRedisTemplate stringRedisTemplate;

    @Test
    public void testStringTemplate(){

        ValueOperations<String, String> ops = stringRedisTemplate.opsForValue();

        //保存
        ops.set("hello","world_"+ UUID.randomUUID().toString());

        //查询
        String hello = ops.get("hello");
        System.out.println("查询数据"+hello);
    }
```

###### 1 缓存穿透 

缓存一个不存在的数据

 查询一个不存在的数据，缓存中不存在，去查数据库，数据库也不存在。没有把结果存到缓存中。以后每次查询都要到数据库去查，返回不存在的结果！

风险：

利用不存在的数据进行攻击，数据库瞬时压力增大。最终导致崩溃

解决

数据不存在，把null存入缓存中并加入短暂过期时间。

###### 2 缓存雪崩

![image-20210326084146938](G:\note\image\image-20210326084146938.png)

大面积的缓存数据同时过期，大量数据同时查询DB

解决

在原有的失效时间增加一个随机的值。1-5分钟，方式缓存数据同时过期

###### 3 缓存击穿



![image-20210218090459298](G:\note\image\image-20210218090459298.png)

分布式锁的演进

![image-20210219181319160](G:\note\image\image-20210219181319160.png)

###### 4 redis存复杂对象

redis内存复杂对象存入时转成json字符串，取出时转为对象类型取出

```properties
 //数据
        TestRedis obj = new TestRedis("小明", 20, "河南");
        //存入时转为json
        String jsonString = JSON.toJSONString(obj);
            redisTemplate.opsForValue().set("user",jsonString);

         //取出user json 字符串
        String user = redisTemplate.opsForValue().get("user");
        //取出时转为我们需要的对象
        TypeReference<TestRedis> typeReference = new TypeReference<TestRedis>() {};
        TestRedis testRedis = JSON.parseObject(user,typeReference);
        System.out.println(testRedis);
```

5  redis 存储数据为了解决缓存击穿问题  热点key失效防止大量请求同时查询数据可 在如果redis中的热点key不存在去查询数据库 代码库用分布式锁 锁起来 ，只允许一个人去查询。查询到结果存入redis中，释放锁，后来请求可以去redis中取出数据

###### 分布式锁

```java
  @Test
    public void testRedis(){

         //如果缓存中有直接取出  如果没有查询数据库 在放入缓存
        String user = redisTemplate.opsForValue().get("user");
        if(user == null){
            //数据         去查询数据库 为了防止多人查询数据库在下面添加分布式锁
            TestRedis obj = new getCatalogJsonFromDbWithRedisLock;
            //存入json字符串
            String jsonString = JSON.toJSONString(obj);
            redisTemplate.opsForValue().set("user",jsonString);
//            return obj;
        }
        //取出时转为我们需要的对象
        TypeReference<TestRedis> typeReference = new TypeReference<TestRedis>() {};
        TestRedis testRedis = JSON.parseObject(user,typeReference);
        System.out.println(testRedis);
    }
```

添加分布式锁 只允许一人查询

```java

//分布式锁
    public Map<String,List<Catelog2Vo>> getCatalogJsonFromDbWithRedisLock() {
        // 1 占分布式锁，去redis占坑 设置过期时间
        String uuid = UUID.randomUUID().toString();
        //如果redis中不存在lock这个key就set成功 如果存在就set失败，所以多线程内只有一个人能set成功，也就只有一个人能进入方法
        Boolean lock = redisTemplate.opsForValue().setIfAbsent("lock", uuid,300, TimeUnit.MINUTES);
            // 1 加锁成功
            if(lock){
                System.out.println("调取分布式锁成功。。。");
                //执行业务
                Map<String,List<Catelog2Vo>> dataFromDb;
                try{//获取数据
                    dataFromDb = getDataFromDb();
                }finally {
                    //删除锁的脚本
                    String script = "if redis.call('get',KYES[1]) == ARGV[1] then return redis.call('del',KEYS[1]) else return 0 end";
                    //指定del
               Long lock1 = redisTemplate.execute(new DefaultRedisScript<Integer>(script,Integer.class),Arrays.asList("lock"),uuid);
                }
//                String lockValue = redisTemplate.opsForValue().get("lock");
//                // 如果值相同就是自己的值，
//                if(uuid.equals(lockValue)){
//                    //删除我自己的锁
//                    redisTemplate.delete("lock");//删除锁
//                }
                return getDataFromDb();
            }else{
                // 加锁失败... 重试
                // 休眠100ms重试
                System.out.println("获取分布式锁失败...等待重试");
                try {
                    Thread.sleep(200);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }      //加锁失败调用自己再次重试
                return  getCatalogJsonFromDbWithRedisLock();
            }

    }

```

上边写分布锁比较麻烦  下面有redisson分布式锁

#### redisson分布式锁



1 引入依赖

```xml
<dependency>
    <groupId>org.redisson</groupId>
    <artifactId>redisson</artifactId>
    <version>3.15.2</version>
</dependency
```

2 配置 RedissonClient

所有对redisson的操作都要通过此Client

```java
@Configuration
public class MyRedissonConfig {
    @Bean(destroyMethod = "shutdown")
    public RedissonClient redisson(){
        //1 创建配置
        Config config = new Config();
        config.useSingleServer().setAddress("redis://192.168.56.10:6379");
        //2 根据配置创建出实例
        RedissonClient redissonClient = Redisson.create(config);
        return redissonClient;
    }
}
```

3 使用

大量迸发情况下只有一人通过请求

```java
    @GetMapping("/hello")
    @ResponseBody
    public String hello(){
        // 1 获取一把锁，只要锁的名字一样，就是一把锁
        RLock lock = redissonClient.getLock("my-lock");
        //2 加锁
        lock.lock(); //阻塞式等待 锁会自动续期，如果业务超长，运行期间自动添加30s时间
                     // 加锁的业务只要运行成功，就不会给当前续期，即使不手动解锁
        // lock.lock(10,TimeUnit.SECONDS); 如果自己加锁过期时间，自动过期时间一定要大于业务执行时间，否则到期了不会自动续期
        //内部原理
        //1 如果我们传了过期时间，就发送给redis执行脚本，进行占锁，默认超时就是我们的过期时间
        //2 如果未指定过期时间，就用30*1000【LockWatchdogTimeout看门狗默认过期时间】
        // 只要占锁成功，就会启动一个定时任务【重新给锁设置过期时间，新的过期时间就是看门狗默认时间】
        // internalLockLeaseTime【看门狗时间】/3   ,10s
        try{
            System.out.println("加锁成功，执行业务"+Thread.currentThread().getId());
            Thread.sleep(30000);
        }catch (Exception e){

        }finally {
            //解锁
            System.out.println("释放锁。。。"+Thread.currentThread().getId());
            lock.unlock();
        }
        return "hello";
    }
```

###### 读写锁

只有写锁释放才能读，保证读取最新的数据

```java
 @GetMapping("/write")
    @ResponseBody
    public String writeValue(){
        RReadWriteLock readWriteLock = redissonClient.getReadWriteLock("rw-lock");
        String s="";
        RLock rLock = readWriteLock.writeLock();
        try {
            rLock.lock();
            s = UUID.randomUUID().toString();
            Thread.sleep(30000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        } finally {
            rLock.unlock();
        }
        return s;
    }

    @GetMapping("/read")
    @ResponseBody
    public String ReadValue(){
        RReadWriteLock readWriteLock = redissonClient.getReadWriteLock("rw-lock");
        String s="";
        RLock rLock = readWriteLock.readLock();
        try {
            rLock.lock();
            s = UUID.randomUUID().toString();
            Thread.sleep(30000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        } finally {
            rLock.unlock();
        }
        return s;
    }
```

###### 信号量

可以用来分布式限流

首先在redis出入信号量的key值park 为3

![image-20210516005120562](G:\note\image\image-20210516005120562.png)

获取信号量

```java
 @GetMapping("/park")
    public String park(){
        //获取一个信号量
        RSemaphore park = redissonClient.getSemaphore("park");
        boolean b = park.tryAcquire(); //如果没有释放超过三次就位false
        if(b){
            //执行获取到信号量的业务
        }else{
            //没有获取到信号量
        }
        return "ok=>"+b;
    }
```

释放信号量

```java
@GetMapping("/go")
    public String go(){
        //获取一个信号量
        RSemaphore park = redissonClient.getSemaphore("park");
        //释放一个信号量
        park.release();
        return "ok";
    }
```

###### 闭锁

```java
  @GetMapping("/lockDoor")
    public String lockDor() throws InterruptedException {
        RCountDownLatch door = redissonClient.getCountDownLatch("door");
        door.trySetCount(5); //设定五把锁
        door.await();  //  只有消耗完了才能继续执行
        return "锁用完了";
    }

    @GetMapping("/gogo/{id}")
    public String gogo() {
        RCountDownLatch door = redissonClient.getCountDownLatch("door");
        door.countDown();  //消耗一把锁
        return "消耗一把锁";
    }
```





![image-20210326135905753](G:\note\image\image-20210326135905753.png)

![image-20210326140434035](G:\note\image\image-20210326140434035.png)

![image-20210326155423477](G:\note\image\image-20210326155423477.png)

![image-20210516092133844](G:\note\image\image-20210516092133844.png)

###### 解决缓存一致性

1 双写模式   更新数据时同时跟新缓存内容

2 失效模式    更新数据时删掉缓存，下次查询时如果缓存没有自动去数据库查

#### SpringCache

```properties
@Cacheable 触发数据保存到缓存的操作
@CacheEvict 删除缓存数据、
@CachePut 更新缓存
@Caching 组合多个缓存操作
@CacheConfig 在类级别共享缓存的相同配置
```

 1 引入依赖

```
spring-boot-starter-cache
spring-boot-starter-data-redis

启动类上添加  @EnableCaching
```

2 写配置

```properties
1 自动配置
spring.cache.type=redis
spring.cache.redis.time-to-live=360000
# key前缀
spring.cache.redis.key-prefix=CACHE_
# 是否使用前缀
spring.cache.redis.use-key-prefix=true
#是否缓存空值
spring.cache.redis.cache-null-values=true

CacheAutoConfiguration会导入RedisCacheConfiguration自动配置好缓存管理器RedisCacheManager
```

新建配置类

让缓存到redis中的数据为json

```java
@EnableConfigurationProperties(CacheProperties.class)
@EnableCaching
@Configuration
public class MyCacheConfig {

    @Bean
    RedisCacheConfiguration redisCacheConfiguration(CacheProperties cacheProperties){
        RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig();
        // 数据转为json格式缓存
        config = config.serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer()));
        config = config.serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer()));
        //读取配置文件的时间
        CacheProperties.Redis redisProperties = cacheProperties.getRedis();
        if (redisProperties.getTimeToLive() != null) {
            config = config.entryTtl(redisProperties.getTimeToLive());
        }

        if (redisProperties.getKeyPrefix() != null) {
            config = config.prefixKeysWith(redisProperties.getKeyPrefix());
        }

        if (!redisProperties.isCacheNullValues()) {
            config = config.disableCachingNullValues();
        }

        if (!redisProperties.isUseKeyPrefix()) {
            config = config.disableKeyPrefix();
        }


        return config;
    }
}
```

3 使用

```java
在方法上添加 @Cacheable  如果缓存中有直接读取，如果没有方法的返回值会自动缓存到redis中
    //sync 加锁
@Cacheable(value = {"cache"},key = "'name'",sync=true)
    @GetMapping("/cache")
    @ResponseBody
    public String cache(){
    return "小明";
}
@CacheEvict(value = {"cache"},key = "'name'")
@GetMapping("/delecache")
@ResponseBody
public String deleCache(){
    return "删除成功";
}

```

#### 线程池

所有的异步任务交给线程池，减少内存，资源浪费

1 原生线程池

```properties
       //将所有的多线程异步任务交给线程池执行
//        原生线程池 七大参数
//        int corePoolSize, 线程池核心数量 一直存在
//        int maximumPoolSize,  最大线程池数量
//        long keepAliveTime,  超出核心线程数的空闲线程等待任务的时间，如果大于时间没有任务就释放
//        TimeUnit unit,  时间单位
//        BlockingQueue<Runnable> workQueue:阻塞队列  线程达到了最大线程数 如果还有任务就方法任务队列里
//          threadFactory  线程的创建工厂
//           handler:  如果阻塞队列满了  按照我们指定拒绝策略  拒绝执行任务
        ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(20,
                100,
                30,
                TimeUnit.MINUTES,
                new LinkedBlockingDeque<>(100000), //默认是Integer的值，造成内存不够 需要手动限制
                Executors.defaultThreadFactory(),  //默认线程工厂
                new ThreadPoolExecutor.AbortPolicy());//拒绝策略
//        一个线程池 core 7 max 20 queue20 100并发怎么分配
//          7 个立即执行
//          50 个进入队列
//          再开13个执行
//          剩下30个使用拒绝策略
```

异步编排

```java
 //线程池
    public static ExecutorService executor = Executors.newFixedThreadPool(10);
    @Test
    public void testCompletableFuture() throws ExecutionException, InterruptedException {
        //线程池
        //异步任务类似javascript promise
        //第一种异步任务
        CompletableFuture.runAsync(()->{
            System.out.println("当前线程"+Thread.currentThread().getId());
            int i = 10/2;
            System.out.println("运行结果"+i);
        },executor);

        //第二种步任务 有返回值
        // whenComplete 接受第一的结果 和异常 继续执行第二步任务 不能改变结果
        //  whenCompleteAsync 让线程池开启新的线程执行第二步任务 不能改变结果
        CompletableFuture<Integer> future = CompletableFuture.supplyAsync(() -> {
            System.out.println("当前线程" + Thread.currentThread().getId());
            int i = 10 / 2;
            System.out.println("运行结果" + i);
            return i;
        }, executor).whenComplete((res,e)->{   //使用与第一步相同的线程
            System.out.println("第一步完成的结果"+res);
            System.out.println("异常"+e);
        }).exceptionally((e)->{ //处理异常 同时返回默认值
            return 10;
        });
        //获取返回值
        Integer integer = future.get();
         //  handle 感知上步处理结果  可以对结果进行处理 改变返回结果
        CompletableFuture<Integer> future2 = CompletableFuture.supplyAsync(() -> {
            System.out.println("当前线程" + Thread.currentThread().getId());
            int i = 10 / 2;
            System.out.println("运行结果" + i);
            return i;
        }, executor).handle((res,e)->{
            return res+100;
        });
        //获取异步任务的结果
        Integer integer1 = future2.get();

    }
```

###### 线程串行化

![image-20210516135930878](G:\note\image-20210516135930878.png)

```java
       CompletableFuture<Integer> future3 = CompletableFuture.supplyAsync(() -> {
            System.out.println("当前线程" + Thread.currentThread().getId());
           int i = 10 / 2;
            System.out.println("运行结果" + i);
            return i;
        }, executor).thenApplyAsync((res)->{ //接受上步任务并可以有返回值
            int i = res + 100;
            return i;
        });
        //获取
        Integer integer2 = future3.get();
        //线程串行话
```

###### 两任务组合

![image-20210516140756995](G:\note\image-20210516140756995.png)

```java
 CompletableFuture<Integer> future1 = CompletableFuture.supplyAsync(() -> {
            System.out.println("当前线程" + Thread.currentThread().getId());
            int i = 10 / 2;
            System.out.println("运行结果" + i);
            return i;
        }, executor);
        CompletableFuture<Integer> future2= CompletableFuture.supplyAsync(() -> {
            System.out.println("当前线程" + Thread.currentThread().getId());
            int i = 10 / 2;
            System.out.println("运行结果" + i);
            return i;
        }, executor);
        future1.thenCombineAsync(future2,(f1,f2)->{
            System.out.println(f1);
            System.out.println(f2);
            return f1+f2;
        },executor);
        Integer integer3 = future2.get();
```

###### 两个任务有一个完成就行

![image-20210516141825558](G:\note\image-20210516141825558.png)

```java
 CompletableFuture<Integer> future1 = CompletableFuture.supplyAsync(() -> {
            System.out.println("当前线程" + Thread.currentThread().getId());
            int i = 10 / 2;
            System.out.println("运行结果" + i);
            return i;
        }, executor);
        CompletableFuture<Integer> future4= CompletableFuture.supplyAsync(() -> {
            System.out.println("当前线程" + Thread.currentThread().getId());
            int i = 10 / 2;
            System.out.println("运行结果" + i);
            return i;
        }, executor);
        future1.applyToEitherAsync(future4,(f1)->{
            return "有一个完成了";
        },executor);
```

###### 多任务组合

![image-20210516142048573](G:\note\image-20210516142048573.png)

```java
   CompletableFuture<String> future1 = CompletableFuture.supplyAsync(() -> {
            System.out.println("任务1");
            return "任务1";
        }, executor);
        CompletableFuture<String> future2 = CompletableFuture.supplyAsync(() -> {
            System.out.println("任务2");
            try {
                Thread.sleep(1000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            return "任务2";
        }, executor);
        CompletableFuture<String> future3 = CompletableFuture.supplyAsync(() -> {
            System.out.println("任务3");
            return "任务3";
        }, executor);
        //等待所有任务完成
        CompletableFuture<Void> future = CompletableFuture.allOf(future1, future2, future3);
        future.get();
        //等前面任务执行完在执行下面代码
        System.out.println("6666");
        //等待其中一个完成
        CompletableFuture<Object> objectCompletableFuture = CompletableFuture.anyOf(future1, future2, future3);
        String o = (String) objectCompletableFuture.get();
        System.out.println(o);
```



#### 短信验证码

###### 集成短信服务

1 根据淘宝上给出的demo

```java
@ConfigurationProperties(prefix = "spring.cloud.alicloud.sms")
@Data
@Component
public class SmsComponent {
    private String host;
    private String path;
    private String appcode;
    private String templateId;
    private String method="POST";

    public void sendSmsConde(String phone,String code){
        Map<String, String> headers = new HashMap<String, String>();
        //最后在header中的格式(中间是英文空格)为Authorization:APPCODE 83359fd73fe94948385f570e3c139105
        headers.put("Authorization", "APPCODE " + appcode);
        Map<String, String> querys = new HashMap<String, String>();
        querys.put("receive", phone);
        querys.put("tag", code);
        querys.put("templateId", templateId);
        Map<String, String> bodys = new HashMap<String, String>();


        try {
            HttpResponse response = null;
            try {
                response = HttpUtils.doPost(host, path, method, headers, querys, bodys);
            } catch (Exception exception) {
                exception.printStackTrace();
            }
            System.out.println(response.toString());
            //获取response的body
            try {
                System.out.println(EntityUtils.toString(response.getEntity()));
            } catch (IOException ioException) {
                ioException.printStackTrace();
            }
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
```

配置文件

```yml
spring:
  cloud:
    nacos:
      discovery:
        server-addr: 127.0.0.1:8848
    alicloud:
      sms:
        host: https://smssend.shumaidata.com
        path: /sms/send
        appcode: 31f26419abdf4c01b8835af01e43714c
        templateId: M09DD535F4
```

HttpUtils 为模板代码给出的网址服务下来即可

在本服务中创建controller方法可以让其他服务调用本方法

```java
@RequestMapping("/sms")
public class SmsController {
    @Autowired
    SmsComponent smsComponent;

    @PostMapping("/sendCode")
    public R sendCode(@RequestParam ("phone") String phone,
                      @RequestParam ("code") String code){
        smsComponent.sendSmsConde(phone,code);
        return R.ok().put("phone",phone).put("code",code);
    }
}

```

###### 引入短信服务

在需要使用的短信验证的服务映入openFeign

引入短信验证feign接口

```java
@FeignClient("gulimall-third-party")
public interface ThirdPartFeignService {
    @PostMapping("/sms/sendCode")
    public R sendCode(@RequestParam("phone") String phone, @RequestParam("code") String code);
}
```

调用接口

```java
@Autowired
    ThirdPartFeignService thirdPartFeignService;

    @Autowired
    StringRedisTemplate stringRedisTemplate;

    @GetMapping("/login")
    @ResponseBody
    public R loginPage(@RequestParam ("phone") String phone){
        // 接口防刷
        //获取redis验证码
        String s = stringRedisTemplate.opsForValue().get(AuthServerConstant.SMS_CODE_CACHE_PREFIX + phone);
        if(!StringUtils.isEmpty(s)){
            long time = Long.parseLong(s.split("_")[1]);
            if(System.currentTimeMillis() - time <60000){
                //60秒内不能再发
                return R.error(BizCodeEnume.SMS_CODE_EXCEPTION);
            }
        }


        //生成验证码 + 系统当前时间超过60秒不能再发
        String code = UUID.randomUUID().toString().substring(0, 5);
        //redis存储验证码
        stringRedisTemplate.opsForValue().set(AuthServerConstant.SMS_CODE_CACHE_PREFIX+phone,code+"_"+System.currentTimeMillis(),10, TimeUnit.MINUTES);

        R r = thirdPartFeignService.sendCode(phone, code);
        return r;
    }
```

#### 注册工程

1 根据页面传入的数据创建vo类并做简单校验

```java
@Data
public class UserRegistVo {
    @NotEmpty(message = "用户名不能为空")
    @Length(min = 6,max = 18,message = "用户名必须为6-18为字符")
    private String userName;

    @NotEmpty(message = "号码不能为空")
    @Pattern(regexp = "^[1]([3-9])[0-9]{9}$",message = "手机号不正确")
    private String phone;

    @NotEmpty(message = "密码不能为空")
    @Length(min = 6,max = 18,message = "密码必须为6-18为字符")
    private String password;

    @NotEmpty(message = "验证码不能为空")
    private String code;
}
```

2 注册方法

```java
     // @Valid开启校验
    // BindingResult result 校验的信息绑定在result中
    @PostMapping("/regist")
    public String regist(@Valid UserRegistVo vo, BindingResult result){
       if(result.hasErrors()){
           HashMap<String, String> errors = new HashMap<>();
//           result.getFieldErrors().stream().map(fieldError -> {
//               String field = fieldError.getField();
//               String defaultMessage = fieldError.getDefaultMessage();
//               errors.put(field,defaultMessage);
//           })
           result.getFieldErrors().stream().collect(Collectors.toMap(FieldError::getField,FieldError::getDefaultMessage));
       }
       return "reg";
    }
}
```

#### session共享

当服务器创建完session对象后，会把session对象的id以cookie形式返回给客户端。这样，当用户保持当前浏览器的情况下再去访问服务器时，会把session的id传给服务器，服务器根据session的id来为用户提供相应的服务。

![image-20210330175629028](G:\note\image\image-20210330175629028.png)

![image-20210330175646139](G:\note\image\image-20210330175646139.png)

###### 解决session共享

![image-20210330202815675](G:\note\image\image-20210330202815675.png)

![image-20210330202859899](G:\note\image\image-20210330202859899.png)

![image-20210330202931706](G:\note\image\image-20210330202931706.png)

![image-20210330203007852](G:\note\image\image-20210330203007852.png)

#### session存到redis

1 现在服务内配置好redis

2 引入

```
<dependency>
    <groupId>org.springframework.session</groupId>
    <artifactId>spring-session-data-redis</artifactId>
    <version>2.2.4.RELEASE</version>
</dependency>
```

3 配置文件

```java
配置文件
spring.session.store-type=redis
server.servlet.session.timeout=30m

    
配置类
@Configuration
public class GulimallSessionConfig {
    //序列化session存入到redis中
    @Bean
    public CookieSerializer cookieSerializer(){
        DefaultCookieSerializer defaultCookieSerializer = new DefaultCookieSerializer();
        defaultCookieSerializer.setDomainName("gulimall.com"); //域名方法可以让每个服务都能使用
        defaultCookieSerializer.setCookieName("GULISESSION");
        return defaultCookieSerializer;
    }

    @Bean
    public RedisSerializer<Object> springSessionDefaultResisSerializer(){
        return new GenericJackson2JsonRedisSerializer();
    }
}
```

4 启动类添加注解

```
@EnableRedisHttpSession
```

5 存数据

```java
@GetMapping("/testsession")
    @ResponseBody
    public String testSession(HttpSession session){
        session.setAttribute("testSession","小明");
        return "testSession";
    }
```

其他服务获取session的数据 

首先步骤同上配置好

```java
@RestController
public class TestSession {
    @GetMapping("/getsession")
    public String getSession(HttpSession session){
        Object testSession = session.getAttribute("testSession");
        System.out.println(testSession);
        return "getsession";
    }
}
```

#### 购物车

为了提升性能购物车数据存到redis中，对redis做持久化防止数据丢失

![image-20210331142539606](G:\note\image\image-20210331142539606.png)

#### RabbitMQ

![image-20210331162550138](G:\note\image\image-20210331162550138.png)

![image-20210331162756200](G:\note\image\image-20210331162756200.png)![image-20210331163045480](G:\note\image\image-20210331163045480.png)

![image-20210331164545378](G:\note\image\image-20210331164545378.png)





![image-20210331170051083](G:\note\image\image-20210331170051083.png)

###### docker 安装RabbitMQ

![image-20210331170651965](G:\note\image\image-20210331170651965.png)

```
docker run -d --name rabbitmq -p 5671:5671 -p 5672:5672 -p 4369:4369 -p 25672:25672 -p 15671:15671 -p 15672:15672 rabbitmq:management
```

1 访问

```
http://192.168.111.133:15672/#/
账户密码 guest
```

![image-20210331172822346](G:\note\image\image-20210331172822346.png)

![image-20210331173135745](G:\note\image\image-20210331173135745.png)

![image-20210331173433671](G:\note\image\image-20210331173433671.png)1 创建交换机

![image-20210331174832132](G:\note\image\image-20210331174832132.png)

2 创建队列

![image-20210331174844626](G:\note\image\image-20210331174844626.png)

3 交换机绑定队列

![image-20210331174912688](G:\note\image\image-20210331174912688.png)

###### 整合RabbitMQ

![image-20210331190012433](G:\note\image\image-20210331190012433.png)

2配置文件

```
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-amqp</artifactId>
    <version>2.2.2.RELEASE</version>
</dependency>
```

```properties
spring.rabbitmq.port=5672
spring.rabbitmq.host=192.168.111.156
#虚拟主机
spring.rabbitmq.virtual-host=/
```

3启动类添加注解 @EnableRabbit

4 使用

```java
 @Autowired
    AmqpAdmin amqpAdmin;

    @Autowired
    RabbitTemplate rabbitTemplate;
    //创建交换机
    @Test
    public void createExchange() {
        DirectExchange directExchange = new DirectExchange("hello-java-exchange",true,false);
        amqpAdmin.declareExchange(directExchange);
        System.out.println("交换机创建成功");
    }
   //创建队列
    @Test
    public void createQueue(){
        Queue queue = new Queue("hello-java.queue", true, false, false, null);
        amqpAdmin.declareQueue(queue);
    }

    //创建队列
    @Test
    public void createBinding(){
                                  // 要绑定的队列名                       绑定的类型                       交换机名字                  路由键                   其他参数
        Binding binding = new Binding("hello-java-queue", Binding.DestinationType.QUEUE, "hello-java-exchange", "hello.java",null);
        amqpAdmin.declareBinding(binding);
    }

    //发送消息
    public void sendMessage(){

        String msg = "发送消息";
        rabbitTemplate.convertAndSend("hello-java-exchange","hello.java",msg);

         //如果要发送对象  自定义配置类把对象序列化为json 对象要实现Serializable
        OrderReturnReasonEntity reasonEntity = new OrderReturnReasonEntity();
        reasonEntity.setId(1L);
        reasonEntity.setCreateTime(new Date());
        reasonEntity.setName("哈哈");
        rabbitTemplate.convertAndSend("hello-java-exchange","hello.java",reasonEntity);
    }

```

接受消息  这个类要注入要内存中

```java
@Service("orderItemService")
public class OrderItemServiceImpl extends ServiceImpl<OrderItemDao, OrderItemEntity> implements OrderItemService {


    //接受消息

    /**
     * queue 声明需要监听的队友队列
     * @param message  原生消息头+体
     * @param content   消息类型
     * @param channel    当前传输数据的通道
     *                   Queue可以被多人监听 某条消息只能被一人接收到
     * @RabbitListener: 添加到类上 指定队列
     * @RabbitHandler 添加到方法上 重载区分不同的消息
     *
     */
    多个方法监听同一个队列 同一个消息只能被一个人接受
        
    @RabbitListener(queues = {"hello-java-queue"})
    public void recieveMessage(Message message, OrderReturnReasonEntity content, Channel channel){
        //消息头
        MessageProperties messageProperties = message.getMessageProperties();
        //消息体
        byte[] body = message.getBody();
        System.out.println("接受到的消息..."+message+"==>内容"+content);
    }

}
```

@RabbitHandler

如果发送方发送的是不同的消息类型

接受方法可在类注释监听的队列 在每个方法内发接受不同的消息类型

```
@RabbitListener(queues = {"hello-java.queue"})
public class receive{
    @RabbitHandler
    public void recieveMessage1(Message message, Object1 content){
        
    }
    @RabbitHandler
    public void recieveMessage1(Message message, Object2 content){

    }
  
}
```

###### 消息确认机制

![image-20210331205126056](G:\note\image\image-20210331205126056.png)



![image-20210331205652719](G:\note\image\image-20210331205652719.png)

发送端确认消息

1. 消息发送至服务器

​     配置文件开启确认

   ```yaml
#消息抵达服务
spring.rabbitmq.publisher-confirm-type=correlated

#消息抵达队列
spring.rabbitmq.publisher-returns=true
#只要抵达队列以异步优先执行确认
spring.rabbitmq.template.mandatory=true
   ```

​    添加配置类

```java
@PostConstruct //对象创建完成后生效
    public  void  initRabbitTemplate(){
        //设置抵达服务器回调
        rabbitTemplate.setConfirmCallback(new RabbitTemplate.ConfirmCallback() {
            /**
             * 确认回调
             * 只要消息抵达服务器 b 就为true
             */
            @Override
            public void confirm(CorrelationData correlationData, boolean b, String s) {
                System.out.println("confirm....correlationData["+correlationData+"]==>ack["+b+"]==>"+s);
            }
        });
        
        //消息抵达队列回调
        rabbitTemplate.setReturnCallback(new RabbitTemplate.ReturnCallback() {
            /**
             * 只要消息没有发送给指定队列值触发这个回调
             * @param error 投递失败的详细信息
             * @param code   回复的状态码
             * @param s  回复的文本内容
             * @param exchange 当时消息要发送给那个交换机
             * @param routeKey  使用的路由键
             */
            @Override
            public void returnedMessage(Message error, int code, String s, String exchange, String routeKey) {
                System.out.println("error"+error);
                System.out.println("code"+code);
                System.out.println(s);
                System.out.println("exchange"+exchange);
                System.out.println("routeKey"+routeKey);
            }
        });
    }
```

接收端消息确认

![image-20210331213841249](G:\note\image\image-20210331213841249.png)

1 开启配置

```properties
#开启手动确认消息  默认为自动回复  接受消息不管处理没有回复消息 队列里自动删除了
# 开启后 虽然接受消息后我们不手动回复  就不会删除  
spring.rabbitmq.listener.simple.acknowledge-mode=manual
```

2 手动确定消息

```java
   @RabbitListener(queues = {"hello-java-queue"})
    public void recieveMessage(Message message, OrderReturnReasonEntity content, Channel channel){
        MessageProperties messageProperties = message.getMessageProperties();
        byte[] body = message.getBody();
        System.out.println("接受到的消息..."+message+"==>内容"+content);
        //消息的一个标志
        long deliveryTag = message.getMessageProperties().getDeliveryTag();
        System.out.println("deliveryTag=>"+deliveryTag);
        //签收货物，
        try {
            if(deliveryTag%2 == 0){
                //收货
                channel.basicAck(deliveryTag,false);
                System.out.println("签收了货物"+deliveryTag);
            }else{
                //退货 requeue = false丢弃 requeue 发回服务器重新入队
                channel.basicNack(deliveryTag,false,false); //拒签后丢弃
                  // 另一种拒签方法
//                channel.basicReject(long deliveryTag, boolean requeue);
            }
        } catch (Exception e){
              //网络中断
        }
    }
```

###### 延时队列

下订单后发消息给队列设置30分钟转给 其他交换机，其他交换机在发送个一个队列  我们的延迟服务区监听这个队列 这里边的消息都是过了30分钟后的  然后在做取消订单操作

![image-20210402134313943](G:\note\image\image-20210402134313943.png)

![image-20210516204823080](G:\note\image-20210516204823080.png)

![image-20210516205004332](G:\note\image\image-20210516205004332.png)



![image-20210402135905914](G:\note\image\image-20210402135905914.png)

![image-20210402140011154](G:\note\image\image-20210402140011154.png)

![image-20210402140551338](G:\note\image\image-20210402140551338.png)

![image-20210402140845479](G:\note\image\image-20210402140845479.png)

代码实现

创建配置类 自动创建Exchange Queue Binding

```java
@Configuration
public class MyMQConfig {
    /**
     * 容器中的 Binding Queue Exchange 都会自动创建
     * @return
     */
    
    //监听消息
    @RabbitListener(queues = "order.release.order.queue")
    public void listener(OrderEntity entity, Channel channel, Message message) throws IOException {
        System.out.println("收到过期订单信息:准备关闭订单"+entity.getOrderSn());

        //手动确认收到消息
        channel.basicAck(message.getMessageProperties().getDeliveryTag(),false);
    }
    
    //交换机order-event-exchange接受消息60秒后发送order-event-exchange路由key为order.release.order
    @Bean
    public Queue orderDelayQueue(){
        Map<String, Object> arguments = new HashMap<>();
        arguments.put("x-dead-letter-exchange","order-event-exchange"); //绑定的交换机
        arguments.put("x-dead-letter-roting-key","order.release.order");
        arguments.put("x-message-ttl","60000"); //延时
        Queue queue = new Queue("order.delay.queue, true, false, false,arguments);
           return queue;
    }
    @Bean
    public Queue orderReleaseOrderQueue(){
        Queue queue = new Queue("order.release.order.queue", true, false, false);
        return queue;
    }
    @Bean
    public Exchange orderEventExchange(){
          return new TopicExchange("order-event-exchange",true,false);
    }
    @Bean
    public Binding orderCreateOrderBingding(){
        Binding binding = new Binding("order.delay.queue", Binding.DestinationType.QUEUE,
                "order-event-exchange", "order.create.order", null);
        return binding;
    }
    @Bean
    public Binding orderReleseOrderBingding(){
        Binding binding = new Binding("order.release.order.queue", Binding.DestinationType.QUEUE,
                "order-event-exchange", "order.release.order", null);
        return binding;
    }

}
```

使用请求发送消息

```java
   @Autowired
    RabbitTemplate rabbitTemplate;

    @GetMapping("/sendMessage")
    @ResponseBody
    public  String createOrderTest(){
        //订单成功
        OrderEntity orderEntity = new OrderEntity();
        orderEntity.setOrderSn(UUID.randomUUID().toString());
        orderEntity.setModifyTime(new Date());
        //发送消息
        rabbitTemplate.convertAndSend("order-event-exchange","order.create.order",orderEntity);
        return "ok";
    }
```

#### 秒杀系统

###### 定时任务

```java
//配置异步任务的线程池
spring.task.scheduling.pool.size=5
spring.task.execution.pool.core-size=20

定时任务会阻塞！
可以使用定时任务+异步任务消除阻塞


@Slf4j
@Component
@EnableAsync   //开启异步任务
@EnableScheduling   //开启定时任务
public class HelloSchedule {

@Async
@Scheduled(corm = "* * * ? * 5")
   public void hello(){
      log.info("hello...");
      Thread.sleep(3000);
   }
}
```

![image-20210403101820778](G:\note\image\image-20210403101820778.png)

![image-20210403102228833](G:\note\image\image-20210403102228833.png)

#### sentinel

###### 整合

1 引入依赖

```xml
  <dependency>
      <groupId>com.alibaba.cloud</groupId>
      <artifactId>spring-cloud-alibaba-sentinel</artifactId>
  </dependency>
```

2 下载sentinel-dashboard客户端

https://github-releases.githubusercontent.com/128018428/cb027680-b243-11e9-855e-775812ee4f39?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210405%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210405T101352Z&X-Amz-Expires=300&X-Amz-Signature=8b3f2e0bc747bbb96bf6e31defd3c194a674d0e30248e4e08d7c9a35058b8312&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=128018428&response-content-disposition=attachment%3B%20filename%3Dsentinel-dashboard-1.6.3.jar&response-content-type=application%2Foctet-stream

3 java -jar sentinel-dashboard.jar --server.port=8080

4 配置文件

```
本服务客户端端口
spring.cloud.sentinel.transport.dashboard=localhost:8333
本服务数据请求端口
spring.cloud.sentinel.transport.port=8719
```

###### 自动定义返回流控规则

```java
@Configuration
public class SenckillSentinelConfig {
    public SenckillSentinelConfig(){
        WebCallbackManager.setUrlBlockHandler(new UrlBlockHandler() {
            @Override
            public void blocked(HttpServletRequest httpServletRequest, HttpServletResponse response, BlockException e) throws IOException {
                R error = R.error("请求次数哦过多");
                response.setCharacterEncoding("UTF-8");
                response.setContentType("application/json");
                response.getWriter().write(JSON.toJSONString(error));
            }
        });
    }
}
```

###### 远程服务控制

1 服务配置  feign.sentinel.enabled=true

2 Feign服务接口配置

```java
@FeignClient(value = "gulimall-seckill",fallback = SeckillServeFallback.class,configuration = FeignConfiguration.class)
public interface SeckillServe {
    @GetMapping("testMessage")
    public String test1();
}

```

```java
@Component
public class SeckillServeFallback implements SeckillServe {
    @Override
    public String test1() {
        return "熔断保护";
    }
}
```

```java
public class FeignConfiguration {
    @Bean
    public SeckillServeFallback seckillServeFallback(){
        return  new SeckillServeFallback();
    }
}
```

自定义受保护的资源

1 @SentinelResource()

#### Sleuth链路追踪

1 服务提供者与消费者都要引入依赖

```java
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-sleuth</artifactId>
    </dependency>
```

Zipkin可视化界面

1 docker 安装zipkin服务器

```lua
docker run -d -p 9411:9411 openzipkin/zipkin
```

2 导入

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-zipkin</artifactId>
</dependency>
如果引用了 zipkin就不用引用 sleuth  内部包含的有
<dependencies>
		<dependency>
			<groupId>org.springframework.cloud</groupId>
			<artifactId>spring-cloud-starter-sleuth</artifactId>
		</dependency>
		<dependency>
			<groupId>org.springframework.cloud</groupId>
			<artifactId>spring-cloud-sleuth-zipkin</artifactId>
		</dependency>
	</dependencies>
```

3 添加zipkin配置

```properties
# 服务器地址
spring.zipkin.base-url=http://192.168.111.133:9411/
# 关闭服务发现
spring.zipkin.discovery-client-enabled=true
# 设置使用http方式传输数据
spring.zipkin.sender.type=web
# 设置采样率为100%  默认为0.1，即10%
spring.sleuth.sampler.probability=1
```

![image-20210406180545751](G:\note\image\image-20210406180545751.png)

数据持久化保存在es中

![image-20210406181359939](G:\note\image\image-20210406181359939.png)

```lua
docker run --env STORAGE_TYPE=elesticsearch --env ES_HOSTS=192.168.111.133:9200 openzipkin/zipkin-dependencies
```

![image-20210406212222296](C:\Users\gg\AppData\Roaming\Typora\typora-user-images\image-20210406212222296.png)![image-20210406212222957](G:\note\image\image-20210406212222957.png)

### 集群篇

k8s 自动部署，扩展和管理容器

